public:
  env_dim: &env_dim 16
  action_dim: &action_dim 4

# DQN Trainer
exp_name: test
train_episode: &dqn_train_episode 25000
strategy: online

# online training parameters
online:
  start_epsilon: 1.0
  end_epsilon: 0.05
  epsilon_decay: 20000

# offline training parameters
offline:
  data_files: ["data/human_2048.json", "data/agent_2048.json"] # Demonstration data files

# replay buffer
buffer:
  size: 100000
  min_size: 10000
  use_per: true
  per_alpha: 0.6
  per_beta_start: 0.4
  per_beta_episode: 10000
  update_interval: 1

# training parameters
batch_size: 128
episode_max_step: 2000
learning_rate:
  warmup_rate: 0.08
  total_steps: *dqn_train_episode
  eta_min: 1.0e-7
  eta_max: 1.0e-4
optimizer: AdamW
network_update_interval: 1
log_interval: 100
save_interval: 2000
output_dir: "outputs/"
from_checkpoint: "" # Path to load a checkpoint
