public:
  env_dim: &env_dim 16
  action_dim: &action_dim 4

# DQN Trainer
exp_name: test
train_episode: &dqn_train_episode 25000
strategy: online

online:
  replay_buffer_update_interval: 1
  replay_buffer_size: 100000
  replay_buffer_size_min: 10000
  start_epsilon: 1.0
  end_epsilon: 0.05
  epsilon_decay: 20000

offline:
  data_files: ["data/human_2048.json", "data/agent_2048.json"] # Demonstration data files

batch_size: 128
episode_max_step: 2000

learning_rate:
  warmup_rate: 0.08
  total_steps: *dqn_train_episode
  eta_min: 1.0e-7
  eta_max: 1.0e-4

optimizer: AdamW
network_update_interval: 1
log_interval: 100
save_interval: 2000
output_dir: "outputs/"
from_checkpoint: "" # Path to load a checkpoint
